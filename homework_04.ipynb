{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework of Ch4. Image Classification using Convolutional Neural Network\n",
    "----\n",
    "This is the homework snippet of TU-ETP-AD1062 Machine Learning Fundamentals.\n",
    "\n",
    "For more information, please refer to:\n",
    "https://sites.google.com/view/tu-ad1062-mlfundamentals/\n",
    "\n",
    "> You do NOT have to build up from nothing, please try your best for the following parts:\n",
    "> - **Your task: HW4.x.y.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.1. Import Packages\n",
    "----\n",
    "- Data pre-processing:\n",
    "    - `os`: Used for path join\n",
    "    - `sklearn.preprocessing.LabelEncoder`: Convert string-based labels into numeric labels\n",
    "    - `PIL.Image`: For image file read and manipulation\n",
    "    - `pandas`: Used for CSV reading and writing\n",
    "- Models construction:\n",
    "    - `models.*`, `layers.*`, and `optimizers.*`: For loading related components layers to constructing convolutional neural network\n",
    "    - `utils.to_categorical`: For converting numerical labels into categorical labels\n",
    "- Performance evaluation:\n",
    "    - `sklearn.metrics.zero_one_loss`: Used for accuracy evaluation\n",
    "    - `sklearn.model_selection.train_test_split`: Divide your data into training and validation set for once, then feed into classifier by yourself, observing the score and confusion matrix\n",
    "    - `mlfund.plot.PlotMetric`: plot confusion matrix (provided by this repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Conv1D, Conv2D, MaxPooling2D, GlobalMaxPooling1D, GlobalAveragePooling2D, Flatten, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mlfund.plot import PlotMetric\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.2. Data pre-processing\n",
    "----\n",
    "The code snippet is used to read image files, with corresponded labels provided in its parent directory, i.e.,\n",
    "- `buildings`\n",
    "- `forest`\n",
    "- `glacier` \n",
    "- `mountain`\n",
    "- `sea`\n",
    "- `street`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW4.2.1. Read Image Files\n",
    "----\n",
    "Prepare image files as `X_train`, which is an `numpy.ndarray` instance, and string-based label list `y_train_str`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "\n",
    "target_size = (32, 32)\n",
    "\n",
    "# Training set\n",
    "X_train = np.empty((0, target_size[0], target_size[1], 3), dtype='uint8')\n",
    "y_train_str = []\n",
    "sha1_train = []\n",
    "\n",
    "for label in labels:\n",
    "    dir_path_current = os.path.join('data', 'hw4', 'train', label)\n",
    "    print('Processing %s ...' % dir_path_current)\n",
    "    \n",
    "    filelist_img = os.listdir(dir_path_current)\n",
    "    \n",
    "    # Images\n",
    "    X_label_set = np.array([np.array(Image.open(os.path.join(dir_path_current, filename_img)).resize( target_size )) for filename_img in filelist_img])\n",
    "    X_train = np.append(X_train, X_label_set, axis=0)\n",
    "    \n",
    "    # Labels\n",
    "    y_train_str = y_train_str + ([label] * len(X_label_set))\n",
    "    \n",
    "    # SHA1\n",
    "    sha1_train = sha1_train + [filename_img.split('.')[0] for filename_img in filelist_img ]\n",
    "    \n",
    "# Shuffle by SHA1\n",
    "idx_sorted = np.argsort(sha1_train)\n",
    "\n",
    "X_train = X_train[idx_sorted, :]\n",
    "y_train_str = np.array(y_train_str)[idx_sorted]\n",
    "sha1_train = np.array(sha1_train)[idx_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing test\n",
    "X_test = np.empty((0, target_size[0], target_size[1], 3), dtype='uint8')\n",
    "sha1_test = []\n",
    "\n",
    "dir_path_current = os.path.join('data', 'hw4', 'test')\n",
    "print('Processing %s ...' % dir_path_current)\n",
    "\n",
    "filelist_img = os.listdir(dir_path_current)\n",
    "    \n",
    "# Images\n",
    "X_test = np.array([np.array(Image.open(os.path.join(dir_path_current, filename_img)).resize( target_size )) for filename_img in filelist_img])\n",
    "\n",
    "# SHA1\n",
    "sha1_test = [filename_img.split('.')[0] for filename_img in filelist_img ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW4.2.2. Convert String Label to Numeric Labels\n",
    "----\n",
    "Use `LabelEncoder` to convert your string lables into `0`, `1`, `2`, ..., and `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train_str)\n",
    "\n",
    "y_train = label_encoder.transform(y_train_str)\n",
    "\n",
    "display( [ (idx, label) for idx, label in enumerate(label_encoder.classes_) ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW4.2.3. Show the First 10 images for each Category\n",
    "----\n",
    "It provides an overview for you to check the dataset read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "\n",
    "for label in np.unique(y_train):\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    \n",
    "    X_label_set = X_train[y_train == label]\n",
    "    \n",
    "    for i in range(0, 10):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow(X_label_set[i,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.3. Construct your Classifier\n",
    "----\n",
    "Build your classifier, with parameters fine-tuned.\n",
    "\n",
    "> **Your task: HW4.3.1.**  \n",
    "> Build your own Neural Network models by Keras framework, try to maximize the performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convNet(num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(100, kernel_size=(3,3), activation='relu', input_shape=(target_size[0], target_size[1], 3)))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Conv2D(50, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50,activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(6,activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2, y1, y2 = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "y1_categorical = to_categorical(y1)\n",
    "y2_categorical = to_categorical(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_convNet(len(label_encoder.classes_))\n",
    "model.summary()\n",
    "model.fit(X1, y1_categorical, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_categorical_predict = model.predict(X2)\n",
    "y2_predict = np.argmax(y2_categorical_predict, axis=1)\n",
    "\n",
    "# Error rate\n",
    "err_01loss = zero_one_loss(y2, y2_predict)\n",
    "print('Error rate = %2.3f' % err_01loss)\n",
    "\n",
    "# Confusion matrix of prediction\n",
    "plot_conf_mat = PlotMetric(figsize=(6,6))\n",
    "plot_conf_mat.set_labels(label_encoder.classes_.tolist())\n",
    "plot_conf_mat.confusion_matrix(y2, y2_predict, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.4. Submit to Kaggle InClass\n",
    "----\n",
    "> **Your task: HW4.4.**\n",
    "> 1. Training with full data set `X_train` with the model created by `create_clf`,\n",
    "> 2. Predict the **unknown** testing data `X_test` by the trained model, then\n",
    "> 3. Submit your result to Kaggle\n",
    "\n",
    "**Notice: You got only 2 chances to submit your result every day, which means you should fine-tune your model by cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and train\n",
    "model = create_clf()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the testing data\n",
    "y_test_predict = model.predict(X_test)\n",
    "y_test_predict_str = label_encoder.inverse_transform(y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you submit\n",
    "----\n",
    "Please join the homework 3 competition by **using the Email ended with \\@trendmicro.com as your Kaggle InClass team name**.\n",
    "\n",
    "Type your Email in the variable `my_trendmicro_email_which_is_also_my_team_name` to make sure you've already read this paragraph, then the following code snippet will help you to generate the csv file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_trendmicro_email_which_is_also_my_team_name = ''\n",
    "\n",
    "\n",
    "import re\n",
    "assert re.match(r\"[^@]+@trendmicro.com\", my_trendmicro_email_which_is_also_my_team_name), \"Please read the instruction above paragraph carefully\"\n",
    "\n",
    "target_path = 'data/hw04.result.csv'\n",
    "df_test_label = pd.DataFrame({'id': df_test_feature['id'], 'label': y_test_predict_str})\n",
    "df_test_label.to_csv(target_path, index=False)\n",
    "\n",
    "print('Congratulation! Please submit your result \\'%s\\' to https://www.kaggle.com/t/' % target_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
